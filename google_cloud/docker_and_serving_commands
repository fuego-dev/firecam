#inspect SavedModel signature from command line
saved_model_cli show --dir aug23_model_SavedModel/ --all

#Make sure this works first
docker run -p 8501:8501   \
  --mount type=bind,source=/home/henry/aug23_model_SavedModel,target=/models/my_model/1 \
  -e MODEL_NAME=my_model -t tensorflow/serving


#list running containers
docker ps

#kill a containter thats running
docker kill CONTAINERID

#remove an old image
docker image ls
docker image rm ID

#explore a container
docker run -t --rm  -i inception_serving /bin/bash




docker pull tensorflow/serving:latest-gpu

sudo docker run -d --name serving_base tensorflow/serving:latest-gpu
sudo docker exec serving_base mkdir -p /models/inception #create intermediate dir
sudo docker cp aug23_model_SavedModel serving_base:/models/inception/1
sudo docker commit --change "ENV MODEL_NAME inception" serving_base inception_serving
sudo docker kill serving_base
sudo docker rm serving_base

#run in background
docker run -p 8500:8500 -t inception_serving &


#setting up nvidia docker
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | sudo apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

#test it
docker run --gpus all nvidia/cuda:9.0-base nvidia-smi


#setting up k8s
following instructions at https://www.tensorflow.org/tfx/serving/serving_kubernetes



kubectl create -f inception_k8s.yaml